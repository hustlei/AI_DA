{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5e27d8",
   "metadata": {},
   "source": [
    "# pytorch tensor学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a19760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import variable\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033469fa",
   "metadata": {},
   "source": [
    "## 创建tensor\n",
    "### 直接创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32a0ac81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "b: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "c: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "d: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.]])\n",
      "e: tensor([[4, 4, 4],\n",
      "        [4, 4, 4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1096, 0.8125, 0.9858],\n",
       "        [0.3045, 0.7077, 0.9974]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.empty(2,3) #与torch.Tensor(2,3)相同，创建一个2x3的未初始化张量\n",
    "b=torch.zeros(2,3) #创建一个全部为0的2x3的张量\n",
    "c=torch.ones(2,3) #创建一个全部为1的2x3的张量\n",
    "d=torch.eye(2,3) #创建一个对角为1的张量\n",
    "e=torch.full((2,3),4) #创建一个全部为指定数字的张量\n",
    "print(\"a:\",a)\n",
    "print(\"b:\",b)\n",
    "print(\"c:\",c)\n",
    "print(\"d:\",d)\n",
    "print(\"e:\",e)\n",
    "#以下方式也可以\n",
    "#shape=(2,3,)\n",
    "#torch.empty(shape)\n",
    "#torch.ones(shape) #创建一个大小为shape的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47701b24",
   "metadata": {},
   "source": [
    "### 从list或者numpy创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc90e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1, 2, 3])\n",
      "b: tensor([2, 2], dtype=torch.int32)\n",
      "b: tensor([3, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3]) #用列表数据新建tesor\n",
    "tmp=np.array([2,2])\n",
    "b=torch.from_numpy(tmp) #用numpy数组创建tensor,新建tensor和numpy数组公用数据\n",
    "print(\"a:\",a)\n",
    "print(\"b:\",b)\n",
    "tmp[:]=[3,3]\n",
    "print(\"b:\",b) #如果tmp[:]=[1,2,3]则会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7673ef86",
   "metadata": {},
   "source": [
    "### tensor的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2324d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(2,3)\n",
    "print(a.size()) #张量的大小\n",
    "print(d.shape) #张量的大小\n",
    "print(d.dtype) #数据类型\n",
    "print(d.device) #设备，设备通常为cpu或gpu(cuda)，指tensor运行的设备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14329d5f",
   "metadata": {},
   "source": [
    "所有创建tensor的函数都可以指定dtype,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f16bcdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,3,dtype=torch.long)\n",
    "torch.ones(2,2,dtype=torch.float64,device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712ffb35",
   "metadata": {},
   "source": [
    "### 根据范围和间距创建tesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4719bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([0, 1, 2, 3, 4])\n",
      "b: tensor([0., 1., 2., 3., 4., 5.])\n",
      "c: tensor([   1.,   10.,  100., 1000.])\n"
     ]
    }
   ],
   "source": [
    "a=torch.arange(0,5,1) #[0,5)步长为1 (troch.range方法相似，表示[0,5]，但已经被废弃)\n",
    "b=torch.linspace(0,5,6) #[0,5]分成6步\n",
    "c=torch.logspace(0,3,4,base=10.0) #base的0次方到3次方，分成4步\n",
    "print(\"a:\",a)\n",
    "print(\"b:\",b)\n",
    "print(\"c:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d4e63",
   "metadata": {},
   "source": [
    "### 随机数创建tesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "729e3bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[0.5884, 0.7072],\n",
      "        [0.6176, 0.9820]])\n",
      "b: tensor([[0, 4, 1],\n",
      "        [2, 1, 3]])\n",
      "c: tensor([1, 6, 9, 2, 5, 0, 7, 3, 4, 8])\n",
      "d: tensor([[-0.4113, -0.1502],\n",
      "        [-0.4428, -1.0307]])   d.mean: tensor(-0.5087)   d.std: tensor(0.3718)\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(2,2) #[0,1)均匀分布\n",
    "b=torch.randint(0,5,(2,3)) #[1,5)整数均匀分布\n",
    "#b=torch.randint(5,(2,2)) #[0,5)\n",
    "c=torch.randperm(10) #[0,10)整数随机分布（官方未说什么分布）\n",
    "d=torch.randn(2,2) #标准正态分布（均值/期望为0，标准差为1）\n",
    "print(\"a:\",a)\n",
    "print(\"b:\",b)\n",
    "print(\"c:\",c)\n",
    "print(\"d:\",d,\"  d.mean:\",d.mean(),\"  d.std:\",d.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c509e",
   "metadata": {},
   "source": [
    "**正态分布采样**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eb670546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard normal dist: tensor([ 7.4819,  9.9577,  9.0413, 10.2628,  9.0897,  8.8479, 10.6109, 11.7441,\n",
      "         9.6896,  9.6596])\n",
      "b: tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "a=torch.normal(10,1,(10,))#正态分布,均值为10，标准差为1）\n",
    "print(\"standard normal dist:\",a)\n",
    "\n",
    "m=torch.arange(0,10.0,1)\n",
    "s=torch.zeros(10)\n",
    "b=torch.normal(m,s) #正态分布采样，每个元素时对应mean参数数值和std参数数值建立的正态分布的一个采样。\n",
    "print(\"b:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ea819",
   "metadata": {},
   "source": [
    "**伯努利分布**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77c03081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a=torch.bernoulli(torch.arange(0,1,0.1)) # 以参数中每个数作为概率（参数张量的值必须是0~1），生成1或0，组成一个张量，即伯努利分布\n",
    "print(\"a:\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e3799",
   "metadata": {},
   "source": [
    "### 根据已有tensor创建(形状与已有tensor无关)\n",
    "\n",
    "> 所有tesor在新地址创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32fcb31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([2, 2, 2])\n",
      "b: tensor([[32370111954616435, 29555306353393756],\n",
      "        [31525678432190556, 27303570963497028]])\n",
      "c: tensor([[0, 0],\n",
      "        [0, 0]])\n",
      "d: tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "e: tensor([[4, 4],\n",
      "        [4, 4]])\n"
     ]
    }
   ],
   "source": [
    "tmp=torch.tensor([1,1])\n",
    "a=tmp.new_tensor([2,2,2])#返回的tensor具有与tmp相同的torch.dtype和torch.device(cpu/gpu)\n",
    "b=tmp.new_empty(2,2)\n",
    "c=tmp.new_zeros(2,2)\n",
    "d=tmp.new_ones(2,2)\n",
    "e=tmp.new_full((2,2),4)\n",
    "print(\"a:\",a)\n",
    "print(\"b:\",b)\n",
    "print(\"c:\",c)\n",
    "print(\"d:\",d)\n",
    "print(\"e:\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f6709",
   "metadata": {},
   "source": [
    "### 根据已有tensor创建(形状与已有tensor相同)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b2fbf111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[3975944217153776948, 3774971281367589986],\n",
      "        [7162263158364845876, 8462385098680267893]])\n",
      "b: tensor([[0, 0],\n",
      "        [0, 0]])\n",
      "c: tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "d: tensor([[4, 4],\n",
      "        [4, 4]])\n",
      "e: tensor([0.1693, 0.6515, 0.3699])\n",
      "f: tensor([2., 0., 3.])\n",
      "g: tensor([-0.4190, -0.5762,  1.1849])\n"
     ]
    }
   ],
   "source": [
    "tmp=torch.tensor([[1,1],[2,2]])\n",
    "a=torch.empty_like(tmp) #形状，数据类型，设备和tmp一样\n",
    "b=torch.zeros_like(tmp)\n",
    "c=torch.ones_like(tmp)\n",
    "d=torch.full_like(tmp,4)\n",
    "tmp=torch.tensor([0.0,1.0,2]) #rand不能创建int，long数据类型，所以tmp为整数类型时，rank_like会报错\n",
    "e=torch.rand_like(tmp)\n",
    "f=torch.randint_like(tmp,0,5)\n",
    "g=torch.randn_like(tmp)\n",
    "print(\"a:\",a)\n",
    "print(\"b:\",b)\n",
    "print(\"c:\",c)\n",
    "print(\"d:\",d)\n",
    "print(\"e:\",e)\n",
    "print(\"f:\",f)\n",
    "print(\"g:\",g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d4a4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# tensor操作\n",
    "## 算术运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a3296c92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b=x+y: tensor([2., 3., 4., 5.])\n",
      "c=torch.add(x,y): tensor([2., 3., 4., 5.])\n",
      "c=b.add(a): tensor([2., 3., 4., 5.])\n",
      "x: tensor([2., 3., 4., 5.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5., 6.])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1.,2.,3.,4.])\n",
    "y=torch.ones(4)\n",
    "b=x+y # 对应元素相加\n",
    "print(\"b=x+y:\",b)\n",
    "c=torch.add(x,y) #同b=x+y\n",
    "print(\"c=torch.add(x,y):\",c)\n",
    "d=x.add(y) #x内容不变，同d=x+y\n",
    "print(\"c=b.add(a):\",c)\n",
    "x+=y  # x,y相加结果,替换b的内容\n",
    "print(\"x:\",x)\n",
    "x.add_(y) #同x+=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b2c88ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([2., 3., 4., 5.])\n",
      "b: tensor([0., 0., 0., 0.])\n",
      "c: tensor([1., 1., 1., 1.])\n",
      "d: tensor([ 1.,  4.,  9., 16.])\n",
      "b1: tensor([-1.,  0.,  1.,  2.])\n",
      "c1: tensor([0.5000, 1.0000, 1.5000, 2.0000])\n",
      "d1: tensor([2., 4., 6., 8.])\n",
      "b2: tensor([0., 0., 0., 0.])\n",
      "c2: tensor([ 1.,  4.,  9., 16.])\n",
      "d2: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1.,2.,3.,4.])\n",
    "# 张量与数字运算时，每个元素与数字运算\n",
    "a=x+1\n",
    "print(\"a:\",a)\n",
    "# 张量与张量运算时，逐个元素对应运算\n",
    "b=x-x\n",
    "c=x/x\n",
    "d=x*x\n",
    "print(\"b:\",b)\n",
    "print(\"c:\",c)\n",
    "print(\"d:\",d)\n",
    "b1=x-2\n",
    "c1=x/2\n",
    "d1=x*2\n",
    "print(\"b1:\",b1)\n",
    "print(\"c1:\",c1)\n",
    "print(\"d1:\",d1)\n",
    "b2=x.sub(x)\n",
    "c2=x.mul(x)\n",
    "d2=x.div(x)\n",
    "print(\"b2:\",b2)\n",
    "print(\"c2:\",c2)\n",
    "print(\"d2:\",d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7633c",
   "metadata": {},
   "source": [
    "## 切片\n",
    "\n",
    "可以使用类似Numpy的切片操作来访问tensor的一部分。\n",
    "切片与原数据共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b3010a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[1., 1., 1., 1.],\n",
      "        [0., 1., 2., 3.]])\n",
      "第一行： tensor([1., 1., 1., 1.])\n",
      "第一列： tensor([1., 0.])\n",
      "修改第一列后： tensor([[5., 1., 1., 1.],\n",
      "        [5., 1., 2., 3.]])\n",
      "第一行修改后两个： tensor([5., 1., 2., 2.])\n",
      "获取第二行的偶数位置： tensor([5., 2.])\n"
     ]
    }
   ],
   "source": [
    "x=torch.empty(2,4)\n",
    "x[0]=torch.ones(4)\n",
    "x[1]=torch.arange(0,4,1)\n",
    "print(\"x:\",x)\n",
    "print(\"第一行：\",x[0,:])\n",
    "print(\"第一列：\",x[:,0])\n",
    "x[:,0]=torch.tensor([5,5])\n",
    "print(\"修改第一列后：\",x)\n",
    "x[0,2:]*=2\n",
    "print(\"第一行修改后两个：\",x[0,:])\n",
    "print(\"获取第二行的偶数位置：\",x[1,0:4:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "397505b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([10,  9,  8,  7,  6,  5,  4,  3,  2,  1])\n",
      "a: tensor([10,  8,  6])\n",
      "b: tensor([10,  9,  8,  7,  6])\n",
      "c: tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n",
      "d: tensor([10,  8,  6])\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(10,0,-1)\n",
    "print(\"x:\",x)\n",
    "a=torch.index_select(x,0,torch.tensor([0,2,4])) #在x中，选择第0维，最后一个参数中位置的值\n",
    "print(\"a:\",a)\n",
    "b=torch.masked_select(x,x>5) #选择指定条件的值\n",
    "print(\"b:\",b)\n",
    "c=torch.nonzero(x) #选择非零元素的下标\n",
    "print(\"c:\",c)\n",
    "d=torch.gather(x,0,torch.tensor([0,2,4])) #同index_select?\n",
    "print(\"d:\",d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7bd40",
   "metadata": {},
   "source": [
    "## 改变形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c721f6",
   "metadata": {},
   "source": [
    "用view()可以得到一个tensor改变形状后的引用,view()返回的tensor与原tensor共享内存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefa494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "b: tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(0,12,1)\n",
    "a=x.view(3,4)\n",
    "print(\"a:\",a)\n",
    "b=x.view(-1,6) #-1所指的维度会自动根据其他维度计算出来\n",
    "print(\"b:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e32fb9",
   "metadata": {},
   "source": [
    "如果想返回不共享内存的新的tensor，使用clone创造一个副本，然后再使用view。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5aa255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "c=x.clone().view(4,-1)\n",
    "print(\"c:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea3d35",
   "metadata": {},
   "source": [
    "tensor使用reshape命令通常和view效果相同，但是在有些情况下会创造个副本再返回view，所以不推荐使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61aff104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1]) y: 1\n"
     ]
    }
   ],
   "source": [
    "#只有一个元素的tensor可以通过item函数得到python number\n",
    "x=torch.tensor([1])\n",
    "y=x.item()\n",
    "print(\"x:\",x,\"y:\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83803a",
   "metadata": {},
   "source": [
    "### 线性代数运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfc5bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "x.trace: tensor(15)\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(0,12,1).view(3,4)\n",
    "print(\"x:\",x)\n",
    "print(\"x.trace:\",x.trace()) #矩阵的迹，对角元素之和\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
